{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This pattern allows the model to make decisions about which path to take through a workflow based on context and intermediate results. The model acts as an intelligent router, directing the flow of execution between different branches of your workflow. This is particularly useful when handling varied inputs that require different processing approaches. In the example below, the results of the first LLM call change the properties of the second LLM call like model size and system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help you with your account! Could you please provide more details about the issue you're experiencing? Whether it's logging in, updating information, or something else, let me know how I can assist you.\n"
     ]
    }
   ],
   "source": [
    "import { generateText, generateObject } from 'ai'\n",
    "import { z } from 'zod'\n",
    "import { createCompatibleOpenAI } from '../../init.ts'\n",
    "\n",
    "const openai = createCompatibleOpenAI()\n",
    "\n",
    "const classificationSchema = z.object({\n",
    "\ttype: z.enum(['general', 'refund', 'technical']),\n",
    "\tcomplexity: z.enum(['simple', 'medium', 'complex']),\n",
    "\treasoning: z.string(),\n",
    "})\n",
    "\n",
    "\n",
    "async function handleCustomerQuery(query: string) {\n",
    "\tconst model = openai('gpt-4o-mini')\n",
    "\n",
    "\t// 1.Classify the query type\n",
    "\tconst { object: classification } = await generateObject<z.infer<typeof classificationSchema>>({\n",
    "\t\tmodel,\n",
    "\t\tschema: z.object({\n",
    "\t\t\ttype: z.enum(['general', 'refund', 'technical']),\n",
    "\t\t\tcomplexity: z.enum(['simple', 'medium', 'complex']),\n",
    "\t\t\treasoning: z.string(),\n",
    "\t\t}),\n",
    "\t\tprompt: `Classify the following customer query:\n",
    "\n",
    "\t\t${query}\n",
    "\n",
    "\t\tDetermine:\n",
    "\t\t1. Query type(general, refund, or technical)\n",
    "\t\t2. Complexity(simple, medium, or complex)\n",
    "\t\t3. Brief reasoning for classification\n",
    "\t\t`\n",
    "\t})\n",
    "\n",
    "\t  // Route based on classification\n",
    "  // Set model and system prompt based on query type and complexity\n",
    "  const { text: response } = await generateText({\n",
    "    model:\n",
    "      classification.complexity === 'simple'\n",
    "        ? openai('gpt-4o-mini')\n",
    "        : openai('o3-mini'),\n",
    "    system: {\n",
    "      general:\n",
    "        'You are an expert customer service agent handling general inquiries.',\n",
    "      refund:\n",
    "        'You are a customer service agent specializing in refund requests. Follow company policy and collect necessary information.',\n",
    "      technical:\n",
    "        'You are a technical support specialist with deep product knowledge. Focus on clear step-by-step troubleshooting.',\n",
    "    }[classification.type],\n",
    "    prompt: query,\n",
    "  });\n",
    "\n",
    "\treturn response\n",
    "}\n",
    "\n",
    "const query = 'I need help with my account'\n",
    "const result = await handleCustomerQuery(query)\n",
    "console.log(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
